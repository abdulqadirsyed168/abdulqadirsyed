# For data load from local
load data local inpath 'file:///tmp/hive_class/depart_data.csv' into table department_data; 

# Load data from hdfs location
load data inpath '/tmp/hive_data_class_2/' into table department_data_from_hdfs;

# Display column name
set hive.cli.print.header = true;

# command to create identical table
create table sales_data_v2_bkup as select * from sales_data_v2;

# To skip first row header in csv
tblproperties ("skip.header.line.count" = "1");

# load data in parquet file for serlizied and deserlizied for serde
from sales_data_v2 insert overwrite table sales_data_pq_final select *;

# set this property if doing static partition
set hive.mapred.mode=strict;

# set this property for dynamic partioning
set hive.exec.dynamic.partition.mode=nonstrict;

# load data in static partition
insert overwrite table sales_data_static_part partition(country = 'USA') select ordernumber,quantityordered,sales,year_id from sales_ord
er_data_orc where country = 'USA';

# load data in dynamic partition table
insert overwrite table sales_data_dynamic_part partition(country) select ordernumber,quantityordered,sales,year_id,country from sales_or
der_data_orc;

# set this property for bucketing
set hive.enforce.bucketing=true;

# Reduce-Side Join
SET hive.auto.convert.join=false;

# Map-Side join
SET hive.auto.convert.join=true;

# Bucket map join
SET hive.auto.convert.join=true;
SET hive.optimize.bucketmapjoin=true;

# Sort-Merge Bucket map join
set hive.optimize.bucketmapjoin = true;
set hive.optimize.bucketmapjoin.sortedmerge = true;
set hive.auto.convert.sortmerge.join=true;
set hive.enforce.sortmergebucketmapjoin=false;



row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' #TO INSERT CSV DATA FILEFORMAT                                                                          
    > with serdeproperties (                                                                                                                  
    >  "separatorChar" = ",",                                                                                                                 
    >  "quoteChar" = "\"",                                                                                                                    
    >  "escapeChar" = "\\"                                                                                                                    
    > )
    
    
In order to set a constant number of reducers:                                                                                                
  set mapreduce.job.reduces=<number> 
  
 # change number of reducers to 3
 
 set mapreduce.job.reduces=3;


create table department_data #INTERNAL TABLES                                                                                                           
    > (                                                                                                                                       
    > dept_id int,                                                                                                                            
    > dept_name string,                                                                                                                       
    > manager_id int,                                                                                                                         
    > salary int)                                                                                                                             
    > row format delimited                                                                                                                    
    > fields terminated by ','
    
# Create external table 
create external table department_data_external                                                                                          
    > (                                                                                                                                       
    > dept_id int,                                                                                                                            
    > dept_name string,                                                                                                                       
    > manager_id int,                                                                                                                         
    > salary int                                                                                                                              
    > )                                                                                                                                       
    > row format delimited                                                                                                                    
    > fields terminated by ','                                                                                                                
    > location '/tmp/hive_data_class_2/'; 
    

# create a table which will store data in parquet

create table sales_data_pq_final                                                                                                        
    > (                                                                                                                                       
    > product_type string,                                                                                                                    
    > total_sales int                                                                                                                         
    > )                                                                                                                                       
    > stored as parquet;  
    
# load data in parquet file
from sales_data_v2 insert overwrite table sales_data_pq_final select *;







