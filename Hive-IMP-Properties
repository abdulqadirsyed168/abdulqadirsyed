# For data load from local
load data local inpath 'file:///tmp/hive_class/depart_data.csv' into table department_data; 

# Load data from hdfs location
load data inpath '/tmp/hive_data_class_2/' into table department_data_from_hdfs;

# Display column name
set hive.cli.print.header = true;

# command to create identical table
create table sales_data_v2_bkup as select * from sales_data_v2;

# set this property if doing static partition
set hive.mapred.mode=strict;

# load data in static partition
insert overwrite table sales_data_static_part partition(country = 'USA') select ordernumber,quantityordered,sales,year_id from sales_ord
er_data_orc where country = 'USA';

# load data in dynamic partition table
insert overwrite table sales_data_dynamic_part partition(country) select ordernumber,quantityordered,sales,year_id,country from sales_or
der_data_orc;

# set this property for dynamic partioning
set hive.exec.dynamic.partition.mode=nonstrict;



row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' #TO INSERT CSV DATA FILEFORMAT                                                                          
    > with serdeproperties (                                                                                                                  
    >  "separatorChar" = ",",                                                                                                                 
    >  "quoteChar" = "\"",                                                                                                                    
    >  "escapeChar" = "\\"                                                                                                                    
    > )
    
    
In order to set a constant number of reducers:                                                                                                
  set mapreduce.job.reduces=<number> 
  
 # change number of reducers to 3
 
 set mapreduce.job.reduces=3;


create table department_data                                                                                                            
    > (                                                                                                                                       
    > dept_id int,                                                                                                                            
    > dept_name string,                                                                                                                       
    > manager_id int,                                                                                                                         
    > salary int)                                                                                                                             
    > row format delimited                                                                                                                    
    > fields terminated by ','
    

# create a table which will store data in parquet

create table sales_data_pq_final                                                                                                        
    > (                                                                                                                                       
    > product_type string,                                                                                                                    
    > total_sales int                                                                                                                         
    > )                                                                                                                                       
    > stored as parquet;  
    
# load data in parquet file
from sales_data_v2 insert overwrite table sales_data_pq_final select *;

