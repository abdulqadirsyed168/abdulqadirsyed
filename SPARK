# DRAWBACKS FOR HADOOP :-
IT WAS MADE BY BATCH PROCESSING
SLOW PROCESSING BECAUSE NOT IN MEMEORY COMPUTATION
NO FAULT TOLERANT IN TERMS OF COMPUTATION 
NO MECHANISM FOR CACHING,PERSISTANCE ETC...

# COMPONENTS OF HADDOP:-
1. HDFS
2. MAD-REDUCE
3. YARN-YET ANOTHER RESOURCE NEGOTITOR.

# APACHE SPARK :-
IT IS DISTRIBUTED COMPUTATION FRAMEWORK
IT DOES NOT HAVE ANY SEPARATED STORAGE OR FILE SYSTEM

# FEATURES OF SPARK :-
1. SPEED : SPARK IS 100 TIME FASTER THAN HADOOP
2. POWERFUL CACHING : CAPABILITIES TO PERSIST DATA INMEMORY
3. DEPLOYMENT : FOR HADOOP DEPLOYMENT WILL HANDEL BY YARN WHILE IN SPARK DEPLOYMENT WOULD HANDEL BY OTHER RESOURCE MANAGER CAN ALSO WORK WITH SPARK
   * YARN
   * MESOS
   * KUBERNETES
   * SPARK OWN CLUSTER MANAGER
   
4. GOOD FIT FOR BATCH AND REAL TIME PROCESSING
5. POLYGLOT :- SPARK PROVIDED HIGH LEVEL API'S ON LIBRARIES FOR DIFFERENT LANGUAGES LIKE 
               * PYTHON
               * JAVA
               * SCALA
               * R
               
               
 # SPARK ARCHITECTURE : SPRAK FOLLOWS MASTER SLAVE ARCHITECTURE AND IT WILL BE KNOWS AS SAPRK MASTER AND SPARK WORKER NODE
 
 1. DRIVER PROGRAM : 
    * IT ACTS LIKE A MAIN METHOD WHICH WILL CREATE THE SPARK CONTEXT
    * THE FIRST METHOD WHICH WILL BE CREATED 
    
 2. SPARK CONTEXT OR SPARK SESSION :
    * IT IS ENTRIE POINT TO THE SPARK CORE OF SPARK APPLICATION
    * IT WILL CONNECT OUR SPARK APPLICATION WITH EXECUTATION ENVIRONMENT OR CLUSTER
    * IT CREATE JOB EXECUTATION GRAPH MANAGES PARTIITONS, SCHEDULING ETC...
    BEFORE SPARK 2.00 SPARK CONTEXT USED SEPARATELY
    AFTER SPARK 2.00+ SPARK SESSION DOES ALL THE THINGS
    
###WITH RESPECT TO SPARK APPLICATIONS###
WHEN WE SUBMIT SPARK APPLICATIONS TO ANY TYPE OF CLUSTER i.e YARN,MESOSE. TWO TYPES OF PROGRAMMES WILL BE GET CREATED 
1.DRIVER PROGRAM : ACTS AS MASTER PROCESS : DRIVER WHICH WILL SUPPLY LOGICS TO ALL NODES WHICH WILL HAVE PARTITIONS
2.EXECUTER PROGRAM : ACTS AS SLAVE PROCESS : EXECUTER WHICH WILL PROCESS DATA WITH LOGICS WITH ONE PARTITION, ALL THE EXECUTER RUN UNDER DRIVER PROGRAM

###WITH RESPECT TO SPARK CLUSTER###
IN YARN CLUSTER MASTER ACTS AS RESOURCE MANAGER
IN YARN CLUSTER SLAVE ACTS AS NODE MANAGER

IN STANDALONE CLUSTER MASTER ACTS AS SPARK MASTER
IN STANDALONE CLUSTER SLAVE ACTS AS SPARK WORKER

WHEN WE SUBMIT SPARK APPLICATION TO SPARK CLUSTER 
RESOURCE MUST BE ALLOCATED TO NODE MANAGER AS SLAVE PROCESS, RESOURCES MEANS (MEMORY AND PROCESSORS)
RESOURCES WILL BE ALLOCATED BY RESOURCE MANAGER TO ALL NODE MANAGERS
LOGIC HAS BEEN SUPPLIED BY SPARK APPLICATION DRIVER TO EACH PARTITIONS 
PARTITON WITH SUPPLIED LOGICS WOULD BE DONE BY EXECUTOR



    
    
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 



