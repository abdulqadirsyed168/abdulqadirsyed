dbutils.fs.mkdirs("/FileStore/Tables/TextFolder") #MAKE Directory

# This two ways we can able to read a file 
Emp_df = spark.read.csv("dbfs:/FileStore/Tables/TextFolder/emp.txt", header=True, inferSchema=True)
Dep_df = spark.read.option("header",True).option("inferSchema",True).csv("dbfs:/FileStore/Tables/TextFolder/dep.txt")


from pyspark.sql.functions import col
from pyspark.sql.functions import *

Dep_df.select("*").show()
Emp_df.select("EMPLOYEE_ID","FIRST_NAME").show()
Emp_df.select(Emp_df.EMPLOYEE_ID,Emp_df.FIRST_NAME).show()
Emp_df.select(Emp_df['EMPLOYEE_ID'],Emp_df['FIRST_NAME']).show()
Emp_df.select(col("employee_id"),col("first_name")).show()
Emp_df.select(col("employee_id").alias("Emp_id"),col("first_name").alias("F_name")).show()

Emp_df.select("employee_id","first_name","salary").withColumn("New_salary",col("SALARY")+1000).show()
Emp_df.withColumn("New_salary",col("salary")+1000).select("employee_id","first_name","new_salary").show()
Emp_df.withColumn("salary",col("salary") - 1000).select("employee_id","first_name","salary").show()
Emp_df.withColumnRenamed("salary","emp_salary").show()

Emp_df.drop("commission_pct").show()
Emp_df.filter(col("salary") < 5000).show()
Emp_df.filter(col("salary") > 5000).show(100)
Emp_df.filter(col("salary") < 5000).select("employee_id","first_name","last_name","salary").show(100)
Emp_df.filter(col("department_id") == 50).select("employee_id","first_name","last_name","salary").show(100)
Emp_df.filter("department_id <> 50").select("employee_id","first_name","last_name","salary","department_id").show(100)
Emp_df.filter("department_id != 50").select("employee_id","first_name","last_name","salary","department_id").show(100)
Emp_df.filter("department_id != 50").filter(col("salary") > 5000).select("employee_id","first_name","last_name","salary","department_id").show(100)
Emp_df.filter("department_id == 50 and salary > 5000").select("employee_id","first_name","last_name","salary","department_id").show(100)

Emp_df.distinct().show(100)
Emp_df.dropDuplicates().show(100)
Emp_df.dropDuplicates(["department_id", "hire_date"]).show(100)
Emp_df.dropDuplicates(["department_id", "hire_date"]).select("employee_id","department_id","hire_date").show(100)


Emp_df.count()
Emp_df.select(count("salary")).show()
Emp_df.select(count("salary").alias("Total_count")).show()
Emp_df.select(max("salary").alias("Max_salary")).show()
Emp_df.select(min("salary").alias("Min_salary")).show()
Emp_df.select(avg("salary").alias("Avg_salary")).show()
Emp_df.select(sum("salary").alias("Sum_salary")).show()

Emp_df.select("*").orderBy("salary").show()
Emp_df.select("*").orderBy(col("salary").desc()).show()
Emp_df.select("*").orderBy(col("salary").desc(),col("department_id").asc()).show()
Emp_df.select("EMPLOYEE_ID","FIRST_NAME","DEPARTMENT_ID","SALARY").orderBy(col("salary").desc(),col("department_id").asc()).show()

Emp_df.groupBy("department_id").sum("salary").show(100)
Emp_df.groupBy("department_id").max("salary").show(100)
Emp_df.groupBy("department_id").min("salary").show(100)
Emp_df.groupBy("department_id","job_id").sum("salary").show(100)
Emp_df.groupBy("department_id","job_id").sum("salary","employee_id").show(100)

Emp_df.groupBy("department_id").agg(sum("salary").alias("Sum_salary"),max("salary").alias("Max_salary"),min("salary").alias("Min_salary"),
avg("salary").alias("Avg_salary")).show(100)
Emp_df.groupBy("department_id").agg(sum("salary").alias("Sum_salary"),max("salary").alias("Max_salary"),min("salary").alias("Min_salary"),
avg("salary").alias("Avg_salary")).where(col("Max_salary") >= 10000).show() 

Emp_df.withColumn("Emp_Grade", when( col("salary") > 15000, "A").when( ( col("salary") >= 10000) & ( col("salary") < 15000), "B").otherwise("C")).show(100)



